
## 注意力模型与用户行为建模
### 1-ATRank -2017-alibaba
[paper describe](https://www.jianshu.com/p/1fe9c66dac4a)
17年的文章，比较早了。首先利用了自注意力机制来建模用户行为历史，根据不同的用户历史行为类别，将用户历史行为商品嵌入投影到不同的特征空间中，期望学习到用户不同行为的内在特征。至于算法框架采用了自注意力和软注意力机制结合的模型，文章的说法是行为交互层和下游网络，但是实验效果的确不错，可以取得比BPR更好的AUC值，值得深入研究。
### 2- DIN - 2018 阿里
[论文简介](https://www.jianshu.com/p/73b6f5d00f46)
在用户历史行为基础上添加attention模型，attention权重由历史用户行为嵌入和候选广告id嵌入通过一个mlp学习得到。与nlp任务中attention模型不同的是，权重并未通过softmax进行归一化，作者认为未经归一化的权重更能表现用户对某种兴趣的青睐
### 3- DIEN - 2018 alibaba
[paper describe](https://www.jianshu.com/p/6742d10b89a8)
将DIN中的无RNN的attention网络结构替换两层RNN模型，并为第一层RNN结构命名为兴趣抽取层，第二层RNN模型命名为兴趣进化层。为了使兴趣抽取层能更好得从用户历史行为中抽取潜在的用户兴趣表达，设计了辅助loss，该辅助loss就是一个交叉熵loss，辅助loss最后会加入总网络的损失loss中，一起学习。作者设计了不同的注意力因子的加入方式，注意力因子直接用来改变第二层RNN结构。
### 4- DSIN - 2019 alibaba
[paper describe](https://www.jianshu.com/p/82ccb10f9ede)
基于session的推荐
### 5-BST  - 2019 alibaba
[papaer describe](https://www.jianshu.com/p/caa2d87cb78c)
就是将transformer引入到推荐中
### 6-NAIS-2018
和DIN创新点几乎差不多，文中作者针对softmax处理长序列进行了一些权重衰减的改进，也考虑了预训练等提高推荐效果。最后实验结果比传统的ALS，BPR等HR和NDCG效果要好。该实验正负样本比例是1:4，数据集为movielens和Pinterest
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyODQ2MDc3MjAsNDM3MTE2MDI1LDExNT
g5Mjc3OTEsMTY0MjYwMzI1MCwxNTMxNjg0NjkwLC0xOTEzOTg4
MzM4LDcyMjg2MzAwNSwtMzk1MjkwODk1LDczMDk5ODExNl19
-->